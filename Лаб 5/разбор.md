# Лабораторная работа: Ансамбли моделей машинного обучения. Часть 1.

## Объяснение работы

### 1. Подготовка данных
Мы продолжаем работать с тем же датасетом о продажах в кофейне. Цель остается прежней - предсказать общую сумму чека (Total_Bill).

**Что было сделано:**
- Удалены дубликаты и пропущенные значения
- Категориальные признаки преобразованы с помощью LabelEncoder (каждому текстовому значению присвоен числовой код)
- Удалены неинформативные столбцы (ID транзакций и т.д.)
- Данные разделены на обучающую (80%) и тестовую (20%) выборки

### 2. Используемые ансамблевые модели

#### Бэггинг (BaggingRegressor)
- Создает несколько параллельных моделей на подвыборках данных (бутстрэп)
- Усредняет их предсказания
- Уменьшает дисперсию ошибки
- Хорошо работает с шумными данными

#### Случайный лес (RandomForestRegressor)
- Разновидность бэггинга для деревьев решений
- Дополнительно выбирает случайное подмножество признаков при каждом разбиении
- Обеспечивает еще большее разнообразие деревьев
- Менее склонен к переобучению

#### AdaBoost (AdaBoostRegressor)
- Последовательно строит ансамбль, где каждая новая модель исправляет ошибки предыдущих
- Присваивает больший вес "сложным" наблюдениям
- Хорошо работает, когда нужно выделить сложные зависимости

#### Градиентный бустинг (GradientBoostingRegressor)
- Также строит ансамбли последовательно
- Оптимизирует специальную функцию потерь с помощью градиентного спуска
- Обычно дает лучшую точность, чем AdaBoost
- Более сложен в настройке

### 3. Метрики оценки

**RMSE (Root Mean Squared Error)** - корень из среднеквадратичной ошибки. Чувствителен к большим ошибкам.

**R² (R-квадрат)** - коэффициент детерминации. Показывает долю объясненной дисперсии.

### 4. Результаты

Из результатов видно, что:
1. Все модели показали отличное качество (R² > 0.99), кроме AdaBoost
2. Лучший результат у Bagging (RMSE = 0.0009, R² = 0.99996)
3. AdaBoost заметно хуже (RMSE = 1.57, R² = 0.928)

**Почему так получилось:**
- Данные достаточно простые и структурированные
- Bagging и Random Forest идеально подходят для таких задач
- AdaBoost хуже работает на задачах регрессии по сравнению с классификацией
- Градиентный бустинг показал результат, сравнимый со случайным лесом

### 5. Рекомендации по улучшению

1. Попробовать другие ансамблевые методы (XGBoost, LightGBM, CatBoost)
2. Настроить гиперпараметры моделей (глубину деревьев, скорость обучения и т.д.)
3. Использовать кросс-валидацию для более надежной оценки
4. Попробовать стекинг (stacking) - комбинацию разных моделей

### Выводы

Лабораторная работа продемонстрировала:
- Применение различных ансамблевых методов
- Их сравнительный анализ на реальных данных
- Сильные и слабые стороны каждого подхода
- Важность выбора метрик оценки

Лучшие результаты показали методы бэггинга (Bagging и Random Forest), что соответствует теории - они особенно эффективны для структурированных табличных данных.