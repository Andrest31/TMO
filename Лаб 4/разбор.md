# Лабораторная работа: Линейные модели, SVM и деревья решений

## Объяснение работы

### 1. Подготовка данных
Мы работаем с датасетом о продажах в кофейне. Цель - предсказать общую сумму чека (Total_Bill) на основе информации о покупке.

**Что было сделано:**
- Удалены лишние столбцы (ID транзакций, даты и т.д.), которые не несут полезной информации для прогнозирования
- Выбрана подвыборка (32% данных) для ускорения работы
- Разделены признаки на категориальные (текстовые) и числовые
- Применено One-Hot Encoding для категориальных признаков (преобразование текстовых значений в числовые)

### 2. Разделение данных
Данные разделены на обучающую (80%) и тестовую (20%) выборки с помощью train_test_split. Это стандартный подход для проверки качества моделей.

### 3. Используемые модели

#### Линейная регрессия
- Простейшая модель, которая ищет линейную зависимость между признаками и целевой переменной
- Плюсы: быстрая, интерпретируемая
- Минусы: плохо работает с нелинейными зависимостями

#### SVM (Support Vector Machine)
- Более сложная модель, которая может находить сложные зависимости
- В данном случае используется для регрессии (SVR)
- Хорошо работает в высокоразмерных пространствах

#### Дерево решений
- Нелинейная модель, которая строит иерархию правил "если-то"
- Может находить сложные зависимости в данных
- Склонно к переобучению на небольших выборках

### 4. Метрики оценки

**MAE (Mean Absolute Error)** - средняя абсолютная ошибка. Показывает, на сколько в среднем ошибается модель.

**R² (R-квадрат)** - показывает, какую долю дисперсии данных объясняет модель. Идеальное значение - 1.0.

### 5. Результаты

Из таблицы видно, что:
1. Дерево решений показало наилучший результат (MAE ≈ 0.006, R² ≈ 0.99)
2. Линейная регрессия показала средние результаты
3. SVM показал худшие результаты в данном случае

Это объясняется тем, что:
- Дерево решений идеально подходит для таких структурированных данных с четкими правилами
- Линейная модель не может уловить все сложные зависимости
- SVM требует тонкой настройки параметров для хорошей работы

### 6. Визуализация важности признаков

Для дерева решений можно построить график важности признаков, который покажет, какие признаки больше всего влияют на прогноз. В данном случае наиболее важными, скорее всего, окажутся:
- Количество товаров (transaction_qty)
- Цена за единицу (unit_price)
- Категория товара (product_category)

### Выводы

Лучшей моделью для данного набора данных оказалось дерево решений. Однако в реальных задачах следует:
1. Попробовать другие модели (случайный лес, градиентный бустинг)
2. Настроить гиперпараметры моделей
3. Проверить модели на кросс-валидации
4. Убедиться, что дерево решений не переобучается
